{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tracker import tracker\n",
    "\n",
    "cap = cv2.VideoCapture(\"/home/abhinav/Desktop/ENPM673/Project2/data/challenge_video.mp4\")\n",
    "K = np.array([[  1.15422732e+03,0.00000000e+00,6.71627794e+02],\n",
    "              [  0.00000000e+00,1.14818221e+03,3.86046312e+02],\n",
    "              [  0.00000000e+00,0.00000000e+00,1.00000000e+00]])\n",
    "dist = np.array([ -2.42565104e-01,-4.77893070e-02,  -1.31388084e-03,  -8.79107779e-05,\n",
    "    2.20573263e-02])\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height), max(0,int(center-width)):min(int(center+width),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256):\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "    res = cv2.LUT(image, lookUpTable)\n",
    "    return res\n",
    "def preprocessing(frame):\n",
    "    th = np.median(frame[int(frame.shape[0]/2):,:,:])\n",
    "#     frame = adjust_gamma(frame,gamma=1.5)\n",
    "#     undist = cv2.undistort(frame,K,dist)\n",
    "#     blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "#     median = cv2.medianBlur(blur,5)\n",
    "    \n",
    "    \n",
    "#     gray = cv2.cvtColor(median, cv2.COLOR_BGR2HLS)\n",
    "#     s_channel = gray[:,:,2]\n",
    "#     l_channel = gray[:,:,1]\n",
    "    \n",
    "    #Create mask for S Channel\n",
    "    if th<60:\n",
    "        s_channel = adjust_gamma(frame,gamma=25.0)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_RGB2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 20\n",
    "        s_max = 250\n",
    "\n",
    "        l_min = 150\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    elif th>130:\n",
    "        s_channel = adjust_gamma(frame,gamma=1)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 20\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 220\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    else:\n",
    "        s_channel = adjust_gamma(frame,gamma=1.5)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 20\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 170\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    combined = np.zeros([frame.shape[0],frame.shape[1]])\n",
    "    combined[(mask1==1)|(mask2==1)]=1\n",
    "    mask = np.uint8(255*combined/np.max(combined))\n",
    "#     mask = cv2.inRange(median,np.array([0,190,80]),np.array([255,255,150]))\n",
    "    seg = cv2.bitwise_and(frame,median,mask=mask)\n",
    "    return seg,combined,th\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    seg,combined,th = preprocessing(frame)\n",
    "    #Extract the region of interest and warp to get bird's eye view\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "#     src = np.float32([[w-(0.5-0.08/2),h*0.62],[w*(0.5+0.08/2),h*0.62],[w*(0.5+0.76/2),h*0.935],[w*(0.5-0.76/2),h*0.935]])\n",
    "#     dst = np.array([[0,0],[400,0],[400,600],[0,400]])\n",
    "#     src = np.array([[619,441],[665,441],[1085,667],[324,667]])\n",
    "#     src = np.array([[600,500],[770,500],[1050,680],[350,680]])\n",
    "    dst = np.array([[300,0],[800,0],[800,600],[300,600]])\n",
    "#     dst = np.float32([[w*0.25,0],[0.75*w,0],[0.75*w,h],[0.25*w,h]])\n",
    "    src = np.array([[375,480],[905,480],[1811,685],[-531,685]])\n",
    "#     dst = np.array([[100,0],[w,0],[w,h-100],[100,h-100]])\n",
    "#     dst = np.array([[100,0],[w,0],[w,h-100],[100,h-100]])\n",
    "    H,flag = cv2.findHomography(src,dst)\n",
    "    out= cv2.warpPerspective(seg,H,(w,h))\n",
    "    out_gray = cv2.cvtColor(out,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(out_gray,100,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(out,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "# #     cv2.putText(l_channel,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "#     cv2.putText(combined,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "    ###########################################\n",
    "    \n",
    "    \n",
    "#     window_width = 20\n",
    "#     window_height = 50\n",
    "#     curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "#     window_centroids = curve_centers.find_window_centroids(thresh1)\n",
    "#     # Points used to draw all the left and right windows\n",
    "#     l_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "#     r_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "        \n",
    "#     # points used to find the right & left lanes\n",
    "#     rightx = []\n",
    "#     leftx = []\n",
    "\n",
    "#     # Go through each level and draw the windows \n",
    "#     for level in range(0,len(window_centroids)/2):\n",
    "#         # Window_mask is a function to draw window areas\n",
    "#         # Add center value found in frame to the list of lane points per left, right\n",
    "#         leftx.append(window_centroids[level][0])\n",
    "#         rightx.append(window_centroids[level][1])\n",
    "\n",
    "#         l_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][0],level)\n",
    "#         r_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][1],level)\n",
    "#         # Add graphic points from window mask here to total pixels found \n",
    "#         l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "#         r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "#     # Draw the results\n",
    "#     template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "#     zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "#     template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "#     warpage = np.array(cv2.merge((thresh1,thresh1,thresh1)),np.uint8) # making the original road pixels 3 color channels\n",
    "#     result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "    result,left,right = window_centers(thresh1,out,window_width=50,window_height=20,margin=50,dst=dst)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('s',result)\n",
    "    cv2.imshow('l',frame)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.imshow('test',l_channel)\n",
    "#     cv2.imshow('mask',mask)\n",
    "    if cv2.waitKey(1)& 0xff==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_centers(image,out,window_width,window_height,margin,dst):\n",
    "    left_windows=[]\n",
    "    right_windows =[]\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "#     mid = np.int((dst[0][0]+dst[1][0])/2)\n",
    "    mid = np.int(image.shape[1]/2)\n",
    "    leftHist = np.sum(image[int(h/2):,:mid],axis=0)\n",
    "    rightHist = np.sum(image[int(h/2):,mid:],axis=0)\n",
    "    window = np.ones(window_width)\n",
    "\n",
    "    left = np.argmax(np.convolve(window,leftHist))-int(window_width/2)\n",
    "    right = np.argmax(np.convolve(window,rightHist))-int(window_width/2) +mid\n",
    "    left_windows.append(left)\n",
    "    right_windows.append(right)\n",
    "    \n",
    "    windows = int(h/window_height)\n",
    "    \n",
    "    #Search for nonzero pixels in each window\n",
    "    for win in range(0,int(windows/2)):\n",
    "        level = np.sum(image[(h - (win+1)*window_height):(h - (win)*window_height),:],axis=0)\n",
    "        conv = np.convolve(window,level)\n",
    "        \n",
    "        x_leftMin = int(max((left-margin+window_width/2),0))\n",
    "        x_leftMax = int(min((left+margin+window_width/2),mid))\n",
    "        l_center = np.argmax(conv[x_leftMin:x_leftMax])+int(x_leftMin-window_width/2)\n",
    "        \n",
    "        x_rightMin = int(max((right-margin+window_width/2),mid))\n",
    "        x_rightMax = int(min((right+margin+window_width/2),w))\n",
    "        r_center = np.argmax(conv[x_rightMin:x_rightMax])+int(x_rightMin-window_width/2)\n",
    "        \n",
    "        \n",
    "        y_min = h - (win+1)*window_height\n",
    "        y_max = h - (win)*window_height\n",
    "        \n",
    "        \n",
    "        cv2.rectangle(out,(int(l_center),y_min),(int(l_center+window_width),y_max),(0,255,255),2)\n",
    "        cv2.rectangle(out,(int(r_center),y_min),(int(r_center+window_width),y_max),(255,0,255),2)\n",
    "        \n",
    "        left_windows.append(l_center)\n",
    "        right_windows.append(r_center)\n",
    "    left_inds=[]\n",
    "    left_inds = np.average(left_windows[-15:],axis=0)\n",
    "    right_inds=[]\n",
    "    right_inds=np.average(right_windows[-15:],axis=0)\n",
    "        \n",
    "    return out,left_inds,right_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fb729ed7bf88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;31m#Extract the region of interest and warp to get bird's eye view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fb729ed7bf88>\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#     frame = adjust_gamma(frame,gamma=1.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     undist = cv2.undistort(frame,K,dist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tracker import tracker\n",
    "\n",
    "cap = cv2.VideoCapture(\"/home/abhinav/Desktop/ENPM673/Project2/data/challenge_video.mp4\")\n",
    "K = np.array([[  1.15422732e+03,0.00000000e+00,6.71627794e+02],\n",
    "              [  0.00000000e+00,1.14818221e+03,3.86046312e+02],\n",
    "              [  0.00000000e+00,0.00000000e+00,1.00000000e+00]])\n",
    "dist = np.array([ -2.42565104e-01,-4.77893070e-02,  -1.31388084e-03,  -8.79107779e-05,\n",
    "    2.20573263e-02])\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height), max(0,int(center-width)):min(int(center+width),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256):\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "    res = cv2.LUT(image, lookUpTable)\n",
    "    return res\n",
    "def preprocessing(frame):\n",
    "    th = np.median(frame[int(frame.shape[0]/2):,:,:])\n",
    "#     frame = adjust_gamma(frame,gamma=1.5)\n",
    "#     undist = cv2.undistort(frame,K,dist)\n",
    "#     blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "#     median = cv2.medianBlur(blur,5)\n",
    "    \n",
    "    \n",
    "#     gray = cv2.cvtColor(median, cv2.COLOR_BGR2HLS)\n",
    "#     s_channel = gray[:,:,2]\n",
    "#     l_channel = gray[:,:,1]\n",
    "    \n",
    "    #Create mask for S Channel\n",
    "    if th<60:\n",
    "        s_channel = adjust_gamma(frame,gamma=25.0)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_RGB2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 30\n",
    "        s_max = 250\n",
    "\n",
    "        l_min = 170\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    elif th>130:\n",
    "        s_channel = adjust_gamma(frame,gamma=1)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 20\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 220\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    else:\n",
    "        s_channel = adjust_gamma(frame,gamma=1.5)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 30\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 190\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    combined = np.zeros([frame.shape[0],frame.shape[1]])\n",
    "    combined[(mask1==1)|(mask2==1)]=1\n",
    "    mask = np.uint8(255*combined/np.max(combined))\n",
    "#     mask = cv2.inRange(median,np.array([0,190,80]),np.array([255,255,150]))\n",
    "    seg = cv2.bitwise_and(frame,median,mask=mask)\n",
    "    return seg,combined,th\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    seg,combined,th = preprocessing(frame)\n",
    "    #Extract the region of interest and warp to get bird's eye view\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "#     src = np.float32([[w-(0.5-0.08/2),h*0.62],[w*(0.5+0.08/2),h*0.62],[w*(0.5+0.76/2),h*0.935],[w*(0.5-0.76/2),h*0.935]])\n",
    "#     dst = np.array([[0,0],[400,0],[400,600],[0,400]])\n",
    "    src = np.array([[375,480],[905,480],[1811,685],[-531,685]])\n",
    "#     dst = np.float32([[w*0.25,0],[0.75*w,0],[0.75*w,h],[0.25*w,h]])\n",
    "#     src = np.array([[580,450],[160,h],[1150,h],[740,450]])\n",
    "    dst = np.array([[100,0],[w,0],[w,h-100],[100,h-100]])\n",
    "    H,flag = cv2.findHomography(src,dst)\n",
    "    out= cv2.warpPerspective(seg,H,(w,h-50))\n",
    "    out_gray = cv2.cvtColor(out,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(out_gray,100,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(out,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "# #     cv2.putText(l_channel,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "#     cv2.putText(combined,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "    ###########################################\n",
    "    \n",
    "    \n",
    "#     window_width = 20\n",
    "#     window_height = 50\n",
    "#     curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "#     window_centroids = curve_centers.find_window_centroids(thresh1)\n",
    "#     # Points used to draw all the left and right windows\n",
    "#     l_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "#     r_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "        \n",
    "#     # points used to find the right & left lanes\n",
    "#     rightx = []\n",
    "#     leftx = []\n",
    "\n",
    "#     # Go through each level and draw the windows \n",
    "#     for level in range(0,len(window_centroids)/2):\n",
    "#         # Window_mask is a function to draw window areas\n",
    "#         # Add center value found in frame to the list of lane points per left, right\n",
    "#         leftx.append(window_centroids[level][0])\n",
    "#         rightx.append(window_centroids[level][1])\n",
    "\n",
    "#         l_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][0],level)\n",
    "#         r_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][1],level)\n",
    "#         # Add graphic points from window mask here to total pixels found \n",
    "#         l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "#         r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "#     # Draw the results\n",
    "#     template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "#     zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "#     template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "#     warpage = np.array(cv2.merge((thresh1,thresh1,thresh1)),np.uint8) # making the original road pixels 3 color channels\n",
    "#     result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "    result,left,right = window_centers(thresh1,out,window_width=50,window_height=20,margin=25,dst=dst)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('s',result)\n",
    "    cv2.imshow('l',thresh1)\n",
    "#     cv2.imshow('test',l_channel)\n",
    "#     cv2.imshow('mask',mask)\n",
    "    if cv2.waitKey(1)& 0xff==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
