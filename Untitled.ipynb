{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tracker import tracker\n",
    "\n",
    "cap = cv2.VideoCapture(\"/home/abhinav/Desktop/ENPM673/Project2/data/challenge_video.mp4\")\n",
    "K = np.array([[  1.15422732e+03,0.00000000e+00,6.71627794e+02],\n",
    "              [  0.00000000e+00,1.14818221e+03,3.86046312e+02],\n",
    "              [  0.00000000e+00,0.00000000e+00,1.00000000e+00]])\n",
    "dist = np.array([ -2.42565104e-01,-4.77893070e-02,  -1.31388084e-03,  -8.79107779e-05,\n",
    "    2.20573263e-02])\n",
    "def window_mask(width, height, img_ref, center, level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height), max(0,int(center-width)):min(int(center+width),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256):\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "    res = cv2.LUT(image, lookUpTable)\n",
    "    return res\n",
    "def preprocessing(frame):\n",
    "    th = np.median(frame[int(frame.shape[0]/2):,:,:])\n",
    "#     frame = adjust_gamma(frame,gamma=1.5)\n",
    "#     undist = cv2.undistort(frame,K,dist)\n",
    "#     blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "#     median = cv2.medianBlur(blur,5)\n",
    "    \n",
    "    \n",
    "#     gray = cv2.cvtColor(median, cv2.COLOR_BGR2HLS)\n",
    "#     s_channel = gray[:,:,2]\n",
    "#     l_channel = gray[:,:,1]\n",
    "    \n",
    "    #Create mask for S Channel\n",
    "    if th<60:\n",
    "        s_channel = adjust_gamma(frame,gamma=25.0)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_RGB2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 30\n",
    "        s_max = 250\n",
    "\n",
    "        l_min = 170\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    elif th>130:\n",
    "        s_channel = adjust_gamma(frame,gamma=1)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 20\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 220\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    else:\n",
    "        s_channel = adjust_gamma(frame,gamma=1.5)\n",
    "        undist = cv2.undistort(frame,K,dist)\n",
    "        blur = cv2.bilateralFilter(undist,9,75,75)\n",
    "        median = cv2.medianBlur(blur,5)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(median, cv2.COLOR_BGR2LAB)\n",
    "        s_channel = gray[:,:,2]\n",
    "        s_channel = cv2.Sobel(s_channel,cv2.CV_64F,1,0)\n",
    "        s_channel = np.absolute(s_channel)\n",
    "        s_channel = np.uint8(255*s_channel/np.max(s_channel))\n",
    "        l_channel = gray[:,:,0]\n",
    "        s_min = 30\n",
    "        s_max = 250\n",
    "        \n",
    "        l_min = 190\n",
    "        l_max = 255\n",
    "        \n",
    "        mask1 = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "        mask1[(s_channel>=s_min)&(s_channel[1]<=s_max)]=1\n",
    "        \n",
    "        mask2 = np.zeros([l_channel.shape[0],l_channel.shape[1]])\n",
    "        mask2[(l_channel>=l_min)&(l_channel<=l_max)]=1\n",
    "    \n",
    "    combined = np.zeros([frame.shape[0],frame.shape[1]])\n",
    "    combined[(mask1==1)|(mask2==1)]=1\n",
    "    mask = np.uint8(255*combined/np.max(combined))\n",
    "#     mask = cv2.inRange(median,np.array([0,190,80]),np.array([255,255,150]))\n",
    "    seg = cv2.bitwise_and(frame,median,mask=mask)\n",
    "    return seg,combined,th\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    seg,combined,th = preprocessing(frame)\n",
    "    #Extract the region of interest and warp to get bird's eye view\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "#     src = np.float32([[w-(0.5-0.08/2),h*0.62],[w*(0.5+0.08/2),h*0.62],[w*(0.5+0.76/2),h*0.935],[w*(0.5-0.76/2),h*0.935]])\n",
    "#     dst = np.array([[0,0],[400,0],[400,600],[0,400]])\n",
    "    src = np.array([[375,480],[905,480],[1811,685],[-531,685]])\n",
    "#     dst = np.float32([[w*0.25,0],[0.75*w,0],[0.75*w,h],[0.25*w,h]])\n",
    "#     src = np.array([[580,450],[160,h],[1150,h],[740,450]])\n",
    "    dst = np.array([[100,0],[w,0],[w,h-100],[100,h-100]])\n",
    "    H,flag = cv2.findHomography(src,dst)\n",
    "    out= cv2.warpPerspective(seg,H,(w,h-100))\n",
    "    out_gray = cv2.cvtColor(out,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh1 = cv2.threshold(out_gray,100,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(out,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "# #     cv2.putText(l_channel,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "#     cv2.putText(combined,str(th),(10,500), font, 4,(255,0,0),2,cv2.LINE_AA)\n",
    "    ###########################################\n",
    "    \n",
    "    \n",
    "    window_width = 20\n",
    "    window_height = 50\n",
    "    curve_centers = tracker(Mywindow_width=window_width, Mywindow_height=window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor=15)\n",
    "    window_centroids = curve_centers.find_window_centroids(thresh1)\n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "    r_points = np.zeros([thresh1.shape[0],thresh1.shape[1]])\n",
    "        \n",
    "    # points used to find the right & left lanes\n",
    "    rightx = []\n",
    "    leftx = []\n",
    "\n",
    "    # Go through each level and draw the windows \n",
    "    for level in range(0,len(window_centroids)/2):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,thresh1,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    warpage = np.array(cv2.merge((thresh1,thresh1,thresh1)),np.uint8) # making the original road pixels 3 color channels\n",
    "    result = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the original road image with window results\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('s',result)\n",
    "    cv2.imshow('l',thresh1)\n",
    "#     cv2.imshow('test',l_channel)\n",
    "#     cv2.imshow('mask',mask)\n",
    "    if cv2.waitKey(1)& 0xff==ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for level in range(int(len(window_centroids)/2),len(window_centroids)):\n",
    "    print level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ransac_polyfit(x, y, order=3, n=20, k=100, t=0.1, d=100, f=0.8):\n",
    "    # Thanks https://en.wikipedia.org/wiki/Random_sample_consensus\n",
    "\n",
    "    # n – minimum number of data points required to fit the model\n",
    "    # k – maximum number of iterations allowed in the algorithm\n",
    "    # t – threshold value to determine when a data point fits a model\n",
    "    # d – number of close data points required to assert that a model fits well to data\n",
    "    # f – fraction of close data points required\n",
    "\n",
    "    besterr = np.inf\n",
    "    bestfit = None\n",
    "    for kk in xrange(k):\n",
    "        maybeinliers = np.random.randint(len(x), size=n)\n",
    "        maybemodel = np.polyfit(x[maybeinliers], y[maybeinliers], order)\n",
    "        alsoinliers = np.abs(np.polyval(maybemodel, x)-y) < t\n",
    "        if sum(alsoinliers) > d and sum(alsoinliers) > len(x)*f:\n",
    "            bettermodel = np.polyfit(x[alsoinliers], y[alsoinliers], order)\n",
    "            thiserr = np.sum(np.abs(np.polyval(bettermodel, x[alsoinliers])-y[alsoinliers]))\n",
    "            if thiserr < besterr:\n",
    "                bestfit = bettermodel\n",
    "                besterr = thiserr\n",
    "    return bestfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c305b0683dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mleft_laneFit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "left_laneFit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(histogram[600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[9,2,3,4,5,6,7,8]\n",
    "b = []\n",
    "a.append(b)\n",
    "# max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[9,[2,345],3,4,5,6,7,8,[]]\n",
    "b= min(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in range(len(a)):\n",
    "    if a==[]:\n",
    "        pass\n",
    "    else:\n",
    "        b.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 3, 4, 5, 6, 7, 8, []]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing another pipeline\n",
    "\n",
    "def binary_transform(img, sobel_kernel=3, sc_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    \"\"\" Given an input image it convert the image color space\n",
    "        from RGB to HLS, tekes only the S channel and applies\n",
    "        Sobel thresholding along X axis.\n",
    "\n",
    "        Returns: a color binary image with only those pixels\n",
    "        set to 1 iff the Sobel values were within the sx_thresh\n",
    "        and the S channel values were within the sc_thresh.\n",
    "    \"\"\"\n",
    "    \n",
    "    img = np.copy(img)\n",
    "\n",
    "    # Convert to HSV color space and separate the S channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "\n",
    "    # Use the s_channel\n",
    "    channel = s_channel\n",
    "    \n",
    "    # Sobel x and y\n",
    "    sobel_x = cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # Absolute derivative in x and y\n",
    "    sobel_x_abs = np.absolute(sobel_x)\n",
    "    sobel_y_abs = np.absolute(sobel_y)\n",
    "\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel_x = np.uint8(255*sobel_x_abs/np.max(sobel_x_abs))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sx_binary = np.zeros([scaled_sobel_x.shape[0],scaled_sobel_x.shape[1]])\n",
    "    sx_binary[(scaled_sobel_x >= sx_thresh[0]) & (scaled_sobel_x <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros([s_channel.shape[0],s_channel.shape[1]])\n",
    "    s_binary[(channel >= sc_thresh[0]) & (channel <= sc_thresh[1])] = 1\n",
    "\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros([sx_binary.shape[0],sx_binary.shape[1]]), sx_binary, s_binary))\n",
    "\n",
    "    # Create a binary flat image.\n",
    "    flat_binary = np.zeros([sx_binary.shape[0],sx_binary.shape[1]])\n",
    "    flat_binary[(sx_binary == 1) | (s_binary == 1)] = 1\n",
    "\n",
    "    return flat_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-402d58074a89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mMinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mfinal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_real_world_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdisplay_save_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pipeline Result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "def to_real_world_space(image, warped, Minv, left_fitx, right_fitx, ploty):\n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(warped).astype(np.uint8)\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "Minv = np.linalg.inv(M)\n",
    "final_output = to_real_world_space(img, img_lines, Minv, l_fit, r_fit, ploty)\n",
    "display_save_images([img, final_output], ['Original', 'Pipeline Result'], 'final_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute curve radius    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    #left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    #right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad =  ((1 + (2*left_fit_cr[0] *y_eval*ym_per_pix + left_fit_cr[1])**2) **1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    # Compute car position\n",
    "    m_car = binary_warped.shape[1] / 2\n",
    "    m_lane = (left_fitx[0] + right_fitx[0]) / 2\n",
    "    offset_right_from_center_m = (m_lane-m_car)*xm_per_pix\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    avg_radius_meters = np.mean([left_curverad, right_curverad])\n",
    "    return out_img, avg_radius_meters, offset_right_from_center_m, left_fitx, right_fitx, ploty\n",
    "\n",
    "img_lines, r_meters, right_from_center_m, l_fit, r_fit, ploty = fit_lines(warped)\n",
    "display_save_images([warped, img_lines], ['Original', 'Lines - R: {:.0f} m'.format(r_meters)], 'lines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "class tracker():\n",
    "    \n",
    "    def __init__(self, Mywindow_width, Mywindow_height, Mymargin, My_ym = 1, My_xm = 1, Mysmooth_factor = 15):\n",
    "        #list that stores all the past (left,right,center) set values used for smoothing the output\n",
    "        self.recent_centers = []\n",
    "\n",
    "        # The window pixel width of the center values, used to count pixels inside center windows to determine curve values\n",
    "        self.window_width = Mywindow_width\n",
    "\n",
    "        # The window pixel height of the center values, used to count pixels inside center windows to determine curve values\n",
    "        # breaks the image into vertical levels\n",
    "        self.window_height = Mywindow_height\n",
    "\n",
    "        # The pixel distance in both directions to slide (left_window + right_window) template for searching\n",
    "        self.margin = Mymargin\n",
    "\n",
    "        self.ym_per_pix = My_ym # meters per pixel in vertical axis\n",
    "\n",
    "        self.xm_per_pix = My_xm # meters per pixel in horizontal axis\n",
    "\n",
    "        self.smooth_factor = Mysmooth_factor\n",
    "\n",
    "        # Main tracking function for finding & storing the lane segment positions\n",
    "    def find_window_centroids(self, warped):\n",
    "\n",
    "        window_width = self.window_width\n",
    "        window_height = self.window_height\n",
    "        margin = self.margin\n",
    "\n",
    "        window_centroids = [] # store the (left,right) window centroid positions per level\n",
    "        window = np.ones(window_width) # create our window template that we will use for convolutions\n",
    "\n",
    "        # first find the two starting positions for the left & right lane by using np.sum to get the vertical image slice\n",
    "        # and then np.convolve the vertical image slice with the window template\n",
    "\n",
    "        #sum quarter bottom of image to get slice, could use a different ratio\n",
    "        l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "        l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "        r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "        r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "\n",
    "        # Add what we found for the 1st layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "        minPix = 30\n",
    "        # Go thru each layer looking for max pixel locations\n",
    "        for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "            # convolve the window into the vertical slice of the image\n",
    "            image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "            # Find the best left centroid by using past left center as a reference\n",
    "            # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "            offset = window_width/2\n",
    "            l_min_index = int(max(l_center+offset-margin,0))\n",
    "            l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "            l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "            # Find the best right centroid by using past right center as a reference\n",
    "            r_min_index = int(max(r_center+offset-margin,0))\n",
    "            r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "            r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "            # Add what we found for that layer\n",
    "            window_centroids.append((l_center,r_center))\n",
    "            #the new window form their median position\n",
    "            if len(left_inds)>minPix:\n",
    "                left_curr = np.int(np.mean(x[left_ind]))\n",
    "            if len(right_inds)>minPix:\n",
    "                right_curr = np.int(np.mean(x[right_ind]))\n",
    "\n",
    "        self.recent_centers.append(window_centroids)\n",
    "        # return averaged values of the line centers, helps to keep the markers from sliding too much\n",
    "        return np.average(self.recent_centers[-self.smooth_factor:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram\n",
    "    histogram = np.sum(thresh1[thresh1.shape[0]/2:,:],axis = 0)\n",
    "    plt.plot(histogram)\n",
    "    mid = np.int((dst[0][0]+dst[1][0])/2)\n",
    "#     mid = np.int(histogram.shape[0]/2)\n",
    "    left_lane = np.argmax(histogram[:mid])\n",
    "    right_lane = np.argmax(histogram[mid:])+mid\n",
    "    \n",
    "    wndw = 9\n",
    "    \n",
    "    wndw_ht = np.int(thresh1.shape[0]/wndw)\n",
    "    \n",
    "    nonzero = thresh1.nonzero()\n",
    "    x = np.array(nonzero[0])\n",
    "    y = np.array(nonzero[1])\n",
    "    \n",
    "    left_curr = left_lane\n",
    "    right_curr = right_lane\n",
    "    \n",
    "    margin = 50   \n",
    "    minPix = 10\n",
    "    \n",
    "    #Find indices for left and right pixels\n",
    "    left_inds = []\n",
    "    right_inds = []\n",
    "    \n",
    "    for win in range(wndw):\n",
    "        y_min = thresh1.shape[0] - (win+1)*wndw_ht\n",
    "        y_max = thresh1.shape[0] - (win)*wndw_ht\n",
    "        x_min_left = left_curr - margin\n",
    "        x_max_left = left_curr + margin\n",
    "        x_min_right = right_curr - margin\n",
    "        x_max_right = right_curr + margin\n",
    "        \n",
    "        cv2.rectangle(out,(x_min_left,y_min),(x_max_left,y_max),(255,0,255),2)\n",
    "        cv2.rectangle(out,(x_min_right,y_min),(x_max_right,y_max),(255,0,0),2)\n",
    "        \n",
    "        left_ind = ((y>=y_min)&(y<=y_max)&(x>=x_min_left)&(x<=x_max_left)).nonzero()[0]\n",
    "        right_ind = ((y>=y_min)&(y<=y_max)&(x>=x_min_right)&(x<=x_max_right)).nonzero()[0]\n",
    "#         if len(left_ind) !=0:\n",
    "        left_inds.append(left_ind)\n",
    "#         if len(right_ind) !=0:\n",
    "        right_inds.append(right_ind)\n",
    "        #If no. of white pixels > minPix then start\n",
    "        \n",
    "        #the new window form their median position\n",
    "        if len(left_inds)>minPix:\n",
    "            left_curr = np.int(np.mean(x[left_ind]))\n",
    "        if len(right_inds)>minPix:\n",
    "            right_curr = np.int(np.mean(x[right_ind]))\n",
    "    \n",
    "    left_inds = np.concatenate(left_inds)\n",
    "    right_inds = np.concatenate(right_inds)\n",
    "    sorted(left_inds)\n",
    "    sorted(right_inds)\n",
    "#     x_left = [x[int(min(left_inds))],x[int(max(left_inds))],x[int(np.median(left_inds))]]\n",
    "#     y_left = [y[int(min(left_inds))],y[int(max(left_inds))],y[int(np.median(left_inds))]]\n",
    "#     x_right = [x[int(min(right_inds))],x[int(max(right_inds))],x[int(np.median(right_inds))]]\n",
    "#     y_right = [y[int(min(right_inds))],y[int(max(right_inds))],y[int(np.median(right_inds))]] \n",
    "    x_left = x[left_inds]\n",
    "    x_right = x[right_inds]\n",
    "    y_left = y[left_inds]\n",
    "    y_right = y[right_inds]\n",
    "    print(x_right)\n",
    "    ##################################################\n",
    "    #Fit a Curve using RANSAC\n",
    "#     left_laneFit = ransac_polyfit(x_left, y_left, order=3, n=20, k=100, t=0.1, d=100, f=0.8)\n",
    "#     right_laneFit = ransac_polyfit(x_right, y_right, order=3, n=20, k=100, t=0.1, d=100, f=0.8)\n",
    "    plotx = np.linspace(0,thresh1.shape[0]-1,thresh1.shape[0]/2)\n",
    "    if len(x_left)!=0:    \n",
    "        left_laneFit =  np.polyfit(x_left,y_left,2)\n",
    "        left_fit = left_laneFit[0]*plotx**2 + left_laneFit[1]*plotx + left_laneFit[2]\n",
    "        pts_left = np.vstack((left_fit,plotx)).astype(np.int32).T\n",
    "        cv2.polylines(out,  [pts_left],  False,  (255, 0, 0),  1)\n",
    "    if len(x_right)!=0:\n",
    "        right_laneFit = np.polyfit(x_right,y_right,2)\n",
    "        right_fit = right_laneFit[0]*plotx**2 + right_laneFit[1]*plotx + right_laneFit[2]\n",
    "        pts_right = np.vstack((right_fit,plotx)).astype(np.int32).T\n",
    "        cv2.polylines(out,  [pts_right],  False,  (0, 0, 255),  1)\n",
    "    \n",
    "    \n",
    "    #Plot the generated curves\n",
    "#      left_fit = left_laneFit[0]*plotx**2 + left_laneFit[1]*plotx + left_laneFit[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
